{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwnNlNIEwoZ8"
      },
      "source": [
        "To learn more about accelerating pandas on Colab, see the [10 minute guide](https://colab.research.google.com/github/rapidsai-community/showcase/blob/main/getting_started_tutorials/cudf_pandas_colab_demo.ipynb) or\n",
        " [US stock market data analysis demo](https://colab.research.google.com/github/rapidsai-community/showcase/blob/main/getting_started_tutorials/cudf_pandas_stocks_demo.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwuxHmxllTwN"
      },
      "source": [
        "<div class=\"markdown-google-sans\">\n",
        "\n",
        "## Machine learning\n",
        "</div>\n",
        "\n",
        "With Colab you can import an image dataset, train an image classifier on it, and evaluate the model, all in just [a few lines of code](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/quickstart/beginner.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from CRITIC\n",
        "!pip install func_timeout\n",
        "import func_timeout\n",
        "\n",
        "\n",
        "def safe_execute(code_string: str, keys=None):\n",
        "    def execute(x):\n",
        "        try:\n",
        "            exec(x)\n",
        "            locals_ = locals()\n",
        "            if keys is None:\n",
        "                an = locals_.get('answer', None)\n",
        "            else:\n",
        "                an = [locals_.get(k, None) for k in keys]\n",
        "            return an, \"Done\"\n",
        "        except BaseException as e: # jump wrong case\n",
        "            return None, repr(e)\n",
        "\n",
        "    try:\n",
        "        an, report = func_timeout.func_timeout(3, execute, args=(code_string,))\n",
        "    except func_timeout.FunctionTimedOut:\n",
        "        an = None\n",
        "        report = \"TimeoutError: execution timeout\"\n",
        "\n",
        "    return an, report\n",
        "\n",
        "\n",
        "def _test_safe_excute():\n",
        "    code_string_1 = \"\"\"import numpy as np\n",
        "a = np.array([1, 2, 3])\n",
        "b = np.array([4, 5, 6])\n",
        "an = np.array([4, 5, 6])\n",
        "answer = a + c\"\"\"\n",
        "\n",
        "    code_string_2 = \"\"\"budget = 1000\n",
        "food = 0.3\n",
        "accommodation = 0.15\n",
        "entertainment = 0.25\n",
        "coursework_materials = 1 - food - accommodation - entertainment\n",
        "answer = budget * coursework_materials\n",
        "\"\"\"\n",
        "    an, report = safe_execute(code_string_1)\n",
        "    print(an, report)\n",
        "\n",
        "    an, report = safe_execute(code_string_2)\n",
        "    print(an, report)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    _test_safe_excute()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTld38JiNRjH",
        "outputId": "b4652e11-6be5-43fd-8d88-ad2f19204ecd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting func_timeout\n",
            "  Downloading func_timeout-4.3.5.tar.gz (44 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: func_timeout\n",
            "  Building wheel for func_timeout (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for func_timeout: filename=func_timeout-4.3.5-py3-none-any.whl size=15077 sha256=fd901f1265c3be59bfb0630c47d3425319c15b5932336384983fe4aa684d7d00\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/83/19/b5552bb9630e353f7c5b15be44bf10900afe1abbbfcf536afd\n",
            "Successfully built func_timeout\n",
            "Installing collected packages: func_timeout\n",
            "Successfully installed func_timeout-4.3.5\n",
            "None NameError(\"name 'c' is not defined\")\n",
            "299.99999999999994 Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class API:\n",
        "    def check_api_call_correctness(self, response, groundtruth) -> bool:\n",
        "        \"\"\"\n",
        "        Checks if the response from the API call is correct.\n",
        "\n",
        "        Parameters:\n",
        "        - response (dict): the response from the API call.\n",
        "        - groundtruth (dict): the groundtruth response.\n",
        "\n",
        "        Returns:\n",
        "        - is_correct (bool): whether the response is correct.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "    def call(self, **kwargs) -> dict:\n",
        "        \"\"\"\n",
        "        Calls the API with the given parameters.\n",
        "\n",
        "        Parameters:\n",
        "        - kwargs (dict): the parameters to call the API with.\n",
        "\n",
        "        Returns:\n",
        "        - response (dict): the response from the API call.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "class Calculator(API):\n",
        "    description = 'This API provides basic arithmetic operations: addition, subtraction, multiplication, and division.'\n",
        "    input_parameters = {\n",
        "        'formula': {'type': 'str', 'description': 'The formula that needs to be calculated. Only integers are supported. Valid operators are +, -, *, /, and (, ). For example, \\'(1 + 2) * 3\\'.'},\n",
        "    }\n",
        "    output_parameters = {\n",
        "        'result': {'type': 'float', 'description': 'The result of the formula.'},\n",
        "    }\n",
        "    def __init__(self) -> None:\n",
        "        pass\n",
        "\n",
        "    def check_api_call_correctness(self, response, groundtruth) -> bool:\n",
        "        \"\"\"\n",
        "        Checks if the response from the API call is correct.\n",
        "\n",
        "        Parameters:\n",
        "        - response (dict): the response from the API call.\n",
        "        - groundtruth (dict): the groundtruth response.\n",
        "\n",
        "        Returns:\n",
        "        - is_correct (bool): whether the response is correct.\n",
        "        \"\"\"\n",
        "        re_formula = response['input']['formula'].replace(' ', '')\n",
        "        gt_formula = groundtruth['input']['formula'].replace(' ', '')\n",
        "\n",
        "        if re_formula == gt_formula and response['output'] == groundtruth['output'] and response['exception'] == groundtruth['exception']:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    def call(self, formula: str) -> float:\n",
        "        \"\"\"\n",
        "        Calculates the result of the formula.\n",
        "\n",
        "        Parameters:\n",
        "        - formula (str): the formula that needs to be calculated. Valid operators are +, -, *, /, and (, ). For example, '(1 + 2) * 3'.\n",
        "\n",
        "        Returns:\n",
        "        - result (float): the result of the formula.\n",
        "        - formula (str): the formula that was calculated.\n",
        "        \"\"\"\n",
        "        input_parameters = {\n",
        "            'formula': formula,\n",
        "        }\n",
        "        try:\n",
        "            result = self.calculate(formula)\n",
        "        except Exception as e:\n",
        "            exception = str(e)\n",
        "            return {'api_name': self.__class__.__name__, 'input': input_parameters, 'output': None, 'exception': exception}\n",
        "        else:\n",
        "            return {'api_name': self.__class__.__name__, 'input': input_parameters, 'output': result, 'exception': None}\n",
        "\n",
        "    def calculate(self, formula: str) -> float:\n",
        "        \"\"\"\n",
        "        Calculates the result of the formula.\n",
        "\n",
        "        Parameters:\n",
        "        - formula (str): the formula that needs to be calculated. Valid operators are +, -, *, /, and (, ). For example, '(1 + 2) * 3'.\n",
        "\n",
        "        Returns:\n",
        "        - result (float): the result of the formula.\n",
        "        \"\"\"\n",
        "        # Remove all spaces from the formula\n",
        "        formula = formula.replace(' ', '')\n",
        "\n",
        "        # Check if the formula is valid\n",
        "        if not self.is_valid_formula(formula):\n",
        "            raise Exception('invalid formula')\n",
        "\n",
        "        # Convert the formula to a list\n",
        "        formula = self.convert_formula_to_list(formula)\n",
        "\n",
        "        # Calculate the result\n",
        "        result = self.calculate_formula(formula)\n",
        "\n",
        "        return result\n",
        "\n",
        "    def is_valid_formula(self, formula: str) -> bool:\n",
        "        \"\"\"\n",
        "        Checks if the formula is valid.\n",
        "\n",
        "        Parameters:\n",
        "        - formula (str): the formula that needs to be checked.\n",
        "\n",
        "        Returns:\n",
        "        - is_valid (bool): True if the formula is valid, False otherwise.\n",
        "        \"\"\"\n",
        "        # Check if the formula is empty\n",
        "        if len(formula) == 0:\n",
        "            return False\n",
        "\n",
        "        # Check if the formula contains invalid characters\n",
        "        dot_count = 0\n",
        "        for c in formula:\n",
        "            if c == '.':\n",
        "                dot_count += 1\n",
        "                if dot_count > 1:\n",
        "                    return False\n",
        "            else:\n",
        "                dot_count = 0\n",
        "            if c not in '0123456789+-*/().':\n",
        "                return False\n",
        "\n",
        "        # Check if the formula contains an invalid number of parentheses\n",
        "        if formula.count('(') != formula.count(')'):\n",
        "            return False\n",
        "\n",
        "        # Check if the formula contains an invalid number of operators\n",
        "        if formula.count('+') + formula.count('-') + formula.count('*') + formula.count('/') == 0:\n",
        "            return False\n",
        "\n",
        "        # Check if the formula contains an invalid number of operands\n",
        "        if formula.count('+') + formula.count('-') + formula.count('*') + formula.count('/') + 1 == len(formula):\n",
        "            return False\n",
        "\n",
        "        return True\n",
        "\n",
        "    def convert_formula_to_list(self, formula: str) -> list:\n",
        "        \"\"\"\n",
        "        Converts the formula to a list.\n",
        "\n",
        "        Parameters:\n",
        "        - formula (str): the formula that needs to be converted.\n",
        "\n",
        "        Returns:\n",
        "        - formula_list (list): the formula converted to a list.\n",
        "        \"\"\"\n",
        "        formula_list = []\n",
        "        number = ''\n",
        "        for c in formula:\n",
        "            if c in '0123456789.':\n",
        "                number += c\n",
        "            else:\n",
        "                if number != '':\n",
        "                    formula_list.append(float(number))\n",
        "                    number = ''\n",
        "                formula_list.append(c)\n",
        "        if number != '':\n",
        "            formula_list.append(float(number))\n",
        "\n",
        "        return formula_list\n",
        "\n",
        "    def calculate_formula(self, formula: list) -> float:\n",
        "        \"\"\"\n",
        "        Calculates the result of the formula.\n",
        "\n",
        "        Parameters:\n",
        "        - formula (list): the formula that needs to be calculated.\n",
        "\n",
        "        Returns:\n",
        "        - result (float): the result of the formula.\n",
        "        \"\"\"\n",
        "        # Calculate the result of the parentheses\n",
        "        while '(' in formula:\n",
        "            left_parenthesis_index = formula.index('(')\n",
        "            right_parenthesis_index = formula.index(')')\n",
        "            formula[left_parenthesis_index:right_parenthesis_index + 1] = [self.calculate_formula(formula[left_parenthesis_index + 1:right_parenthesis_index])]\n",
        "\n",
        "        # Calculate the result of the multiplication and division\n",
        "        while '*' in formula or '/' in formula:\n",
        "            if '*' in formula and '/' in formula:\n",
        "                if formula.index('*') < formula.index('/'):\n",
        "                    index = formula.index('*')\n",
        "                else:\n",
        "                    index = formula.index('/')\n",
        "            elif '*' in formula:\n",
        "                index = formula.index('*')\n",
        "            else:\n",
        "                index = formula.index('/')\n",
        "            formula[index - 1:index + 2] = [self.calculate_operation(formula[index - 1], formula[index], formula[index + 1])]\n",
        "\n",
        "        # Calculate the result of the addition and subtraction\n",
        "        while '+' in formula or '-' in formula:\n",
        "            if '+' in formula and '-' in formula:\n",
        "                if formula.index('+') < formula.index('-'):\n",
        "                    index = formula.index('+')\n",
        "                else:\n",
        "                    index = formula.index('-')\n",
        "            elif '+' in formula:\n",
        "                index = formula.index('+')\n",
        "            else:\n",
        "                index = formula.index('-')\n",
        "            formula[index - 1:index + 2] = [self.calculate_operation(formula[index - 1], formula[index], formula[index + 1])]\n",
        "\n",
        "        return formula[0]\n",
        "\n",
        "    def calculate_operation(self, operand1: float, operator: str, operand2: float) -> float:\n",
        "        \"\"\"\n",
        "        Calculates the result of the operation.\n",
        "\n",
        "        Parameters:\n",
        "        - operand1 (float): the first operand.\n",
        "        - operator (str): the operator.\n",
        "        - operand2 (float): the second operand.\n",
        "\n",
        "        Returns:\n",
        "        - result (float): the result of the operation.\n",
        "        \"\"\"\n",
        "        if operator == '+':\n",
        "            return operand1 + operand2\n",
        "        elif operator == '-':\n",
        "            return operand1 - operand2\n",
        "        elif operator == '*':\n",
        "            return operand1 * operand2\n",
        "        elif operator == '/':\n",
        "            return operand1 / operand2\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     # Create the API\n",
        "#     api = Calculator()\n",
        "#     response = api.call('(1+2)* 3')\n",
        "#     print(response[\"output\"])"
      ],
      "metadata": {
        "id": "nGXidBYsNQMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install httpcore\n",
        "!pip install httpcore==0.15.0 httpx pymongo googletrans\n",
        "!pip install openai\n",
        "\n",
        "from googletrans import Translator\n",
        "import openai\n",
        "import time\n",
        "import spacy\n",
        "from googleapiclient.discovery import build\n",
        "from sympy import sympify\n",
        "import datetime\n",
        "\n",
        "cx = \"\"\n",
        "keys = [\"\"]\n",
        "openai.api_key = \"\"\n",
        "openai.api_base = \"\"\n",
        "\n",
        "def split_text(text):\n",
        "    \"\"\"\n",
        "    使用 spaCy 进行句子分割。\n",
        "\n",
        "    参数:\n",
        "    text (str): 要分割的文本。\n",
        "\n",
        "    返回:\n",
        "    list: 分割后的句子列表。\n",
        "    \"\"\"\n",
        "    # 加载英文模型（确保您已经安装并下载了该模型）\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    # 使用 spaCy 处理文本\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # 提取句子\n",
        "    sentences = [sentence.text.strip() for sentence in doc.sents]\n",
        "\n",
        "    return sentences\n",
        "\n",
        "\n",
        "def web_search(sentence, api_keys=keys, lr='lang_en', num=5):\n",
        "    for api_key in api_keys:\n",
        "        try:\n",
        "            service = build(\"customsearch\", \"v1\", developerKey=api_key)\n",
        "            res = (\n",
        "                service.cse()\n",
        "                .list(\n",
        "                    q=sentence,\n",
        "                    cx=cx,\n",
        "                    lr=lr,\n",
        "                    num=num\n",
        "                )\n",
        "                .execute()\n",
        "            )\n",
        "            snippets = []\n",
        "            if 'items' in res:\n",
        "                for result in res['items']:\n",
        "                    if \"snippet\" in result:\n",
        "                        snippets.append(result[\"snippet\"])\n",
        "                fact = \"\\n\".join(snippets)\n",
        "                return fact  # 如果请求成功，返回结果并退出函数\n",
        "            else:\n",
        "                return \"No results found.\"  # 如果没有找到结果，返回相应信息\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred:\\n{e}\")\n",
        "\n",
        "def match(sentence, context):\n",
        "    template = \"Given a piece of text and its corresponding context, please determine whether the text contains incorrect content. If you think there is an error, answer \\\"Yes\\\". Otherwise, answer \\\"No\\\".\\n\\n#Given Text#: {sentence}\\n#Context#: {context}\\n#Your Judgment#:\\n\\n#Given Text#: {sentence}\\n#Context#: {context}\\n#Your Judgment#:\"\n",
        "    input = template.format(sentence=sentence, context=context)\n",
        "    print(input)\n",
        "    message = [\n",
        "        {\"role\": \"user\", \"content\": input},\n",
        "    ]\n",
        "    while True:\n",
        "        try:\n",
        "            res = openai.ChatCompletion.create(\n",
        "                # model=\"gpt-3.5-turbo\",\n",
        "                model=\"gpt-4-turbo\",\n",
        "                messages=message,\n",
        "                temperature=0,\n",
        "            )\n",
        "            break\n",
        "        except openai.error.RateLimitError:\n",
        "            print('openai.error.RateLimitError\\nRetrying...')\n",
        "            time.sleep(20)\n",
        "        except openai.error.ServiceUnavailableError:\n",
        "            print('openai.error.ServiceUnavailableError\\nRetrying...')\n",
        "            time.sleep(20)\n",
        "        except openai.error.Timeout:\n",
        "            print('openai.error.Timeout\\nRetrying...')\n",
        "            time.sleep(20)\n",
        "        except openai.error.APIError:\n",
        "            print('openai.error.APIError\\nRetrying...')\n",
        "            time.sleep(20)\n",
        "        except openai.error.APIConnectionError:\n",
        "            print('openai.error.APIConnectionError\\nRetrying...')\n",
        "            time.sleep(20)\n",
        "    print(\"gpt4:\", res['choices'][0]['message']['content'])\n",
        "    if \"yes\" in res['choices'][0]['message']['content'].lower():\n",
        "        label = 1\n",
        "    elif \"no\" in res['choices'][0]['message']['content'].lower():\n",
        "        label = 0\n",
        "    return label\n",
        "\n",
        "\n",
        "def calculator(sentence, formula):\n",
        "    try:\n",
        "        result = sympify(formula)\n",
        "        if isinstance(result, float):\n",
        "            # 将result转换为字符串，以检查小数点后的位数\n",
        "            result_str = str(result)\n",
        "            # 检查是否存在小数点且小数点后的位数大于4\n",
        "            if '.' in result_str and len(result_str.split('.')[1]) > 4:\n",
        "                # 如果满足条件，保留4位小数\n",
        "                result = round(result, 4)\n",
        "        fact = f\"{formula} = {result}\"\n",
        "        label = match(sentence, fact)\n",
        "        return fact, label\n",
        "    except SyntaxError as e:\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "def get_answer(sentences, labels, facts):\n",
        "    sen = []\n",
        "    for i in range(len(labels)):\n",
        "        if labels[i] == 1:\n",
        "            sen.append({\"sentence\":sentences[i], \"fact\":facts[i]})\n",
        "    if len(sen) == 0:\n",
        "        return \"否。\"\n",
        "    else:\n",
        "        return \"是。\" + str(sen)\n",
        "\n",
        "def word_count(length, text):\n",
        "    # 计算答案的字数\n",
        "    answer_length = len(text)\n",
        "\n",
        "    # 比较答案字数和要求字数，添加标签\n",
        "    label = 0 if answer_length == length else 1\n",
        "\n",
        "    return answer_length, label\n",
        "\n",
        "def code_interpreter(code):\n",
        "    print(code)\n",
        "    an, report = safe_execute(code)\n",
        "    print(an, report)\n",
        "    label = 1\n",
        "    if report == \"Done\":\n",
        "        label = 0\n",
        "    return label, report\n",
        "\n",
        "def translate(text, target_language='en'):\n",
        "    translator = Translator()\n",
        "    result = translator.translate(text, dest=target_language)\n",
        "    return result.text\n",
        "\n",
        "def calculate_days_between_dates(date1, date2):\n",
        "    date_format = \"%Y-%m-%d\"\n",
        "    d1 = datetime.datetime.strptime(date1, date_format)\n",
        "    d2 = datetime.datetime.strptime(date2, date_format)\n",
        "    delta = d2 - d1\n",
        "    return delta.days\n"
      ],
      "metadata": {
        "id": "pitMd9CHEYwg",
        "outputId": "f7f5cf89-b8ca-4e40-b7ea-7e2199ad7e61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: httpcore in /usr/local/lib/python3.10/dist-packages (0.15.0)\n",
            "Requirement already satisfied: h11<0.13,>=0.11 in /usr/local/lib/python3.10/dist-packages (from httpcore) (0.12.0)\n",
            "Requirement already satisfied: sniffio==1.* in /usr/local/lib/python3.10/dist-packages (from httpcore) (1.3.1)\n",
            "Requirement already satisfied: anyio==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpcore) (2024.8.30)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio==3.*->httpcore) (2.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio==3.*->httpcore) (1.2.2)\n",
            "Requirement already satisfied: httpcore==0.15.0 in /usr/local/lib/python3.10/dist-packages (0.15.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.10/dist-packages (4.10.1)\n",
            "Requirement already satisfied: googletrans in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: h11<0.13,>=0.11 in /usr/local/lib/python3.10/dist-packages (from httpcore==0.15.0) (0.12.0)\n",
            "Requirement already satisfied: sniffio==1.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.15.0) (1.3.1)\n",
            "Requirement already satisfied: anyio==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.15.0) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpcore==0.15.0) (2024.8.30)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio==3.*->httpcore==0.15.0) (2.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio==3.*->httpcore==0.15.0) (1.2.2)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo) (2.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from googletrans) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->googletrans) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->googletrans) (2.2.3)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.51.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.25.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.6.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (2.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (0.15.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Requirement already satisfied: h11<0.13,>=0.11 in /usr/local/lib/python3.10/dist-packages (from httpcore->httpx<1,>=0.23.0->openai) (0.12.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from transformers.generation.utils import GenerationConfig\n",
        "\n",
        "# Define helper functions\n",
        "def dump_jsonl(data, output_path, append=False):\n",
        "    \"\"\"\n",
        "    Write list of objects to a JSON lines file.\n",
        "    \"\"\"\n",
        "    mode = 'a+' if append else 'w'\n",
        "    with open(output_path, 'a+', encoding='utf-8') as f:\n",
        "        json_record = json.dumps(data, ensure_ascii=False)\n",
        "        f.write(json_record + '\\n')\n",
        "\n",
        "def init_model(model_path=None):\n",
        "    \"\"\"\n",
        "    Initialize the model and tokenizer.\n",
        "    \"\"\"\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        \"openai-community/gpt2\",\n",
        "        torch_dtype=torch.float16,\n",
        "        device_map=\"auto\",\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "    model.generation_config = GenerationConfig.from_pretrained(\n",
        "        \"openai-community/gpt2\"\n",
        "    )\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\n",
        "        \"openai-community/gpt2\",\n",
        "        use_fast=False,\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "    return model, tokenizer\n",
        "\n",
        "def get_response(messages):\n",
        "    \"\"\"\n",
        "    Get a response from the model based on input messages.\n",
        "    \"\"\"\n",
        "    model, tokenizer = init_model()\n",
        "    response = model.chat(tokenizer, messages)\n",
        "    return response\n",
        "\n",
        "def generate_p(input_path, output_path):\n",
        "    \"\"\"\n",
        "    Process the input JSON and generate output.\n",
        "    \"\"\"\n",
        "    model, tokenizer = init_model()\n",
        "\n",
        "    with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        # Process each line as a separate JSON object\n",
        "        for line in f:\n",
        "            try:\n",
        "                data = json.loads(line.strip())  # Strip any extra whitespace/newline\n",
        "                # Process the data as before\n",
        "                ...\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"JSONDecodeError: {e} - Line: {line.strip()}\")\n",
        "                continue  # Skip this line and move to the next\n",
        "\n",
        "    cnt = 0\n",
        "    res = []\n",
        "    fail_num = []\n",
        "\n",
        "    temp = \"You are an agent tasked with detecting hallucinations in reply texts using a specific framework. Below is a detailed explanation of the detection framework:\\nFirstly, you need to determine whether to split the input reply text into a list of sentences using a sentence segmentation tool. If required, you should check each sentence individually; otherwise, the entire text should be checked as a whole. You can choose an appropriate fact-checking tool to obtain relevant information and knowledge for verification and then use the matching tool to output the judgment results or directly output the judgment results. If you do not use the match tool and directly output the judgment results, you need to output the label in your thought. There is an error output \\\"label = 1\\\"; there is no error output \\\"label = 0\\\". After the verification is completed, you need to reflect on all detection results and output the label in your thought, then call get\\_answer() to produce the final detection result. \\n\\nSentence Splitting Tool: \\nsplit_text(text: str) → sentence_list\\nThis function splits the text into a list of sentences.\\n\\nFact-Checking Tools: \\nweb_search(sentence: str) → fact\\nThis function uses a search engine to find information related to the sentence. After using web_search, you must use the match tool to determine if the reply matches the retrieved information.\\n\\ncalculator(sentence: str, formula: str) → result, label\\nThis function uses a calculator to obtain the result of a formula and checks if the result matches the sentence. If they match, the label is 0; otherwise, it is 1. Valid operators include +, -, *, /, and parentheses. For instance, a valid input could be “(1 + 2) * 3”. If the input is an equation, it needs to be converted to a formula without unknowns.\\n\\nword_count(length: int, text: str) → count, label\\nThis function calculates the word count of a text and outputs the count. If the word count does not meet the specified length, the label is 1; otherwise, it is 0.\\n\\ncode_interpreter() → label\\nThis function checks whether the code can execute correctly. If it executes correctly, the output label is 0; otherwise, it is 1.\\n\\nMatching Tool:\\nmatch(sentence: str, context:str) → label\\nThis function checks a sentence against its context, which might include content from questions and replies around the detected sentence. It looks for irrelevant or contradictory answers. If any are found, the label is 1; otherwise, it is 0. If you think the output of match is wrong, you can correct the label in thought. For example, if you think the \\\"label = 0\\\" output by match is wrong, you can correct the answer and output \\\"label = 1\\\" in thought.\\n\\nEach time it’s your turn to respond, you must strictly follow this format to present your thoughts and actions: \\\"Thought: Your thought process.\\nACTION: Tool call, e.g., match(sentence=\\\"...\\\", context=\\\"...\\\")\\\". After each tool use, I will provide the output as follows: \\\"Observation: Tool's output result\\\".\"\n",
        "\n",
        "    for d in data:\n",
        "        try:\n",
        "            cnt += 1\n",
        "            fnum = 0\n",
        "            messages = []\n",
        "            query = {\"role\": \"user\", \"content\": temp + \" QUERY: \" + d[\"question\"] + \" RESPONSE: \" + d[\"answer\"]}\n",
        "            messages.append(query)\n",
        "\n",
        "            # Get the model's response\n",
        "            ans = model.chat(tokenizer, messages)\n",
        "\n",
        "            # Process the response to extract actions\n",
        "            if \"ACTION:\" in ans:\n",
        "                action = ans.split(\"ACTION:\")[-1].strip(\".\").strip()\n",
        "                if \"\\n\" in action:\n",
        "                    action = action.split(\"\\n\")[0]\n",
        "                ans = ans.split(\"ACTION:\")[0] + \" ACTION: \" + action\n",
        "\n",
        "            # Variables for holding the results\n",
        "            label_list = []\n",
        "            fact_list = []\n",
        "            sen_list = []\n",
        "            web_fact = \"\"\n",
        "\n",
        "            # Loop through actions and tools\n",
        "            while True:\n",
        "                response = \"\"\n",
        "                response0 = \"OBSERVATION:\"\n",
        "                action = ans.split(\"ACTION:\")[-1].strip(\".\").strip(\":\").strip()\n",
        "                print(action)\n",
        "\n",
        "                if \"split\" in action:\n",
        "                    sentences = eval(action)\n",
        "                    response = {\"role\": \"user\", \"content\": response0 + str(sentences)}\n",
        "                elif \"calculator\" in action:\n",
        "                    result, label = eval(action)\n",
        "                    response = {\"role\": \"user\", \"content\": response0 + result + \", label = \" + str(label)}\n",
        "                    sentence = action.split(\"sentence=\")[-1].split(\"\\\"\")[1]\n",
        "                    sen_list.append(sentence)\n",
        "                    fact_list.append(result)\n",
        "                    label_list.append(label)\n",
        "                elif \"web_search\" in action:\n",
        "                    fact = eval(action)\n",
        "                    response = {\"role\": \"user\", \"content\": response0 + fact}\n",
        "                    web_fact = fact\n",
        "                elif \"match\" in action:\n",
        "                    label = eval(action)\n",
        "                    text = \"label = \" + str(label)\n",
        "                    response = {\"role\": \"user\", \"content\": response0 + text}\n",
        "                    sentence = action.split(\"sentence=\")[-1].split(\"\\\"\")[1]\n",
        "                    sen_list.append(sentence)\n",
        "                    fact = action.split(\"context=\")[-1].strip(\"\\\")\")\n",
        "                    fact_list.append(fact)\n",
        "                    label_list.append(label)\n",
        "                elif \"code_interpreter\" in action:\n",
        "                    label, report = eval(action)\n",
        "                    text = \"label = \" + str(label)\n",
        "                    response = {\"role\": \"user\", \"content\": response0 + text}\n",
        "                    sen_list.append(d[\"answer\"])\n",
        "                    fact_list.append(report)\n",
        "                    label_list.append(label)\n",
        "                elif \"word_count\" in action:\n",
        "                    text = d[\"answer\"]\n",
        "                    count, label = eval(action)\n",
        "                    response = {\"role\": \"user\", \"content\": response0 + \"The number of words in this text is \" + str(count) + \", label = \" + str(label)}\n",
        "                    sen_list.append(d[\"answer\"])\n",
        "                    fact_list.append(\"The number of words in this text is \" + str(count))\n",
        "                    label_list.append(label)\n",
        "                elif \"get_answer\" in action:\n",
        "                    fnum += 1\n",
        "                    if fnum > 5:\n",
        "                        break\n",
        "                    if sen_list == []:\n",
        "                        sen_list.append(d[\"answer\"])\n",
        "                        if web_fact:\n",
        "                            fact_list.append(web_fact)\n",
        "                    if label_list == []:\n",
        "                        response = {\"role\": \"user\", \"content\": \"OBSERVATION: The label is not detected, please output the label in THOUGHT like label = 1 or label = 0 and call get_answer() again.\"}\n",
        "                        print(response)\n",
        "                        messages.append(response)\n",
        "                        ans = model.chat(tokenizer, messages)\n",
        "                        if \"ACTION:\" in ans:\n",
        "                            action = ans.split(\"ACTION:\")[-1].strip(\".\").strip()\n",
        "                            thought = ans.split(\"ACTION:\")[0].strip(\".\").strip()\n",
        "                            if \"label=1\" in thought.lower():\n",
        "                                if len(label_list) > 0:\n",
        "                                    label_list[-1] = 1\n",
        "                                else:\n",
        "                                    label_list.append(1)\n",
        "                            elif \"label=0\" in thought.lower():\n",
        "                                if len(label_list) > 0:\n",
        "                                    label_list[-1] = 0\n",
        "                                else:\n",
        "                                    label_list.append(0)\n",
        "                            if \"\\n\" in action:\n",
        "                                action = action.split(\"\\n\")[0]\n",
        "                            ans = ans.split(\"ACTION:\")[0] + \" ACTION: \" + action\n",
        "                        messages.append({\"role\": \"assistant\", \"content\": ans})\n",
        "                        print(ans)\n",
        "                        continue\n",
        "                    final_answer = get_answer(sen_list, label_list, fact_list)\n",
        "                    messages.append({\"role\": \"user\", \"content\": \"OBSERVATION: \" + final_answer})\n",
        "                    break\n",
        "                else:\n",
        "                    print(\"No such tool, failed!\")\n",
        "                    break\n",
        "\n",
        "                # Add the response to the conversation\n",
        "                messages.append(response)\n",
        "                ans = model.chat(tokenizer, messages)\n",
        "                if \"ACTION:\" in ans:\n",
        "                    action = ans.split(\"ACTION:\")[-1].strip(\".\").strip()\n",
        "                    messages.append({\"role\": \"assistant\", \"content\": ans})\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            fail_num.append(cnt)\n",
        "            d[\"final_answer\"] = \"Error\"\n",
        "            d[\"trajectory\"] = messages\n",
        "            res.append(d)\n",
        "            dump_jsonl(d, output_path, append=True)\n",
        "            continue\n",
        "\n",
        "        d[\"final_answer\"] = final_answer\n",
        "        d[\"trajectory\"] = messages\n",
        "        res.append(d)\n",
        "        dump_jsonl(d, output_path, append=True)\n",
        "\n",
        "    print(f\"{len(fail_num)} questions failed processing\")\n",
        "    print(fail_num)\n",
        "\n",
        "# Specify the input and output file paths\n",
        "input_path = \"trajectory_generation_en.jsonl\"  # Change to your uploaded input file name\n",
        "output_path = \"output_file.json\"        # Change to your desired output file name\n",
        "\n"
      ],
      "metadata": {
        "id": "RWBGdu883yex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload the input file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# List uploaded filesx\n",
        "import os\n",
        "print(os.listdir())\n"
      ],
      "metadata": {
        "id": "ezFOxfEc4NOK",
        "outputId": "0d701735-2b87-4c23-81c5-d718e4ed44cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9e53348e-e35a-46eb-9dc1-bab227c35cc9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9e53348e-e35a-46eb-9dc1-bab227c35cc9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "RangeError: Maximum call stack size exceeded.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-63513730d2d3>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Upload the input file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# List uploaded filesx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'complete'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     result = _output.eval_js(\n\u001b[0m\u001b[1;32m    173\u001b[0m         'google.colab._files._uploadFilesContinue(\"{output_id}\")'.format(\n\u001b[1;32m    174\u001b[0m             \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: RangeError: Maximum call stack size exceeded."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the main function\n",
        "generate_p(input_path, output_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "kyypPUjEldlQ",
        "outputId": "b35948de-9966-40cb-8c8c-2bd3c7aca826"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JSONDecodeError: Invalid \\escape: line 1 column 983 (char 982) - Line: {\"role\": \"system\", \"content\": \"You are an agent tasked with detecting hallucinations in reply texts using a specific framework. Below is a detailed explanation of the detection framework:\\nFirstly, you need to determine whether to split the input reply text into a list of sentences using a sentence segmentation tool. If required, you should check each sentence individually; otherwise, the entire text should be checked as a whole. You can choose an appropriate fact-checking tool to obtain relevant information and knowledge for verification and then use the matching tool to output the judgment results or directly output the judgment results. If you do not use the match tool and directly output the judgment results, you need to output the label in your thought. There is an error output \\\"label = 1\\\"; there is no error output \\\"label = 0\\\". After the verification is completed, you need to reflect on all detection results and output the label in your thought, then call get\\_answer() to produce the final detection result. \\n\\nSentence Splitting Tool: \\nsplit_text(text: str) → sentence_list\\nThis function splits the text into a list of sentences.\\n\\nFact-Checking Tools: \\nweb_search(sentence: str) → fact\\nThis function uses a search engine to find information related to the sentence. After using web_search, you must use the match tool to determine if the reply matches the retrieved information.\\n\\ncalculator(sentence: str, formula: str) → result, label\\nThis function uses a calculator to obtain the result of a formula and checks if the result matches the sentence. If they match, the label is 0; otherwise, it is 1. Valid operators include +, -, *, /, and parentheses. For instance, a valid input could be “(1 + 2) * 3”. If the input is an equation, it needs to be converted to a formula without unknowns.\\n\\nword_count(length: int, text: str) → count, label\\nThis function calculates the word count of a text and outputs the count. If the word count does not meet the specified length, the label is 1; otherwise, it is 0.\\n\\ncode_interpreter() → label\\nThis function checks whether the code can execute correctly. If it executes correctly, the output label is 0; otherwise, it is 1.\\n\\nMatching Tool:\\nmatch(sentence: str, context:str) → label\\nThis function checks a sentence against its context, which might include content from questions and replies around the detected sentence. It looks for irrelevant or contradictory answers. If any are found, the label is 1; otherwise, it is 0. If you think the output of match is wrong, you can correct the label in thought. For example, if you think the \\\"label = 0\\\" output by match is wrong, you can correct the answer and output \\\"label = 1\\\" in thought.\\n\\nEach time it’s your turn to respond, you must strictly follow this format to present your thoughts and actions: \\\"Thought: Your thought process.\\nACTION: Tool call, e.g., match(sentence=\\\"...\\\", context=\\\"...\\\")\\\". After each tool use, I will provide the output as follows: \\\"Observation: Tool's output result\\\".\"}\n",
            "string indices must be integers\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'str' object does not support item assignment",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-9af526afb90b>\u001b[0m in \u001b[0;36mgenerate_p\u001b[0;34m(input_path, output_path)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mmessages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" QUERY: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"question\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" RESPONSE: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"answer\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0mmessages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: string indices must be integers",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-f4223bb03dc2>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Call the main function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgenerate_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-39-9af526afb90b>\u001b[0m in \u001b[0;36mgenerate_p\u001b[0;34m(input_path, output_path)\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mfail_num\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"final_answer\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m             \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"trajectory\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'str' object does not support item assignment"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "-\n"
      ],
      "metadata": {
        "id": "hPeBqv955PXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufxBm1yRnruN"
      },
      "source": [
        "Colab is used extensively in the machine learning community with applications including:\n",
        "- Getting started with TensorFlow\n",
        "- Developing and training neural networks\n",
        "- Experimenting with TPUs\n",
        "- Disseminating AI research\n",
        "- Creating tutorials\n",
        "\n",
        "To see sample Colab notebooks that demonstrate machine learning applications, see the [machine learning examples](#machine-learning-examples) below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Rh3-Vt9Nev9"
      },
      "source": [
        "<div class=\"markdown-google-sans\">\n",
        "\n",
        "## More Resources\n",
        "\n",
        "### Working with Notebooks in Colab\n",
        "\n",
        "</div>\n",
        "\n",
        "- [Overview of Colab](/notebooks/basic_features_overview.ipynb)\n",
        "- [Guide to Markdown](/notebooks/markdown_guide.ipynb)\n",
        "- [Importing libraries and installing dependencies](/notebooks/snippets/importing_libraries.ipynb)\n",
        "- [Saving and loading notebooks in GitHub](https://colab.research.google.com/github/googlecolab/colabtools/blob/main/notebooks/colab-github-demo.ipynb)\n",
        "- [Interactive forms](/notebooks/forms.ipynb)\n",
        "- [Interactive widgets](/notebooks/widgets.ipynb)\n",
        "\n",
        "<div class=\"markdown-google-sans\">\n",
        "\n",
        "<a name=\"working-with-data\"></a>\n",
        "### Working with Data\n",
        "</div>\n",
        "\n",
        "- [Loading data: Drive, Sheets, and Google Cloud Storage](/notebooks/io.ipynb)\n",
        "- [Charts: visualizing data](/notebooks/charts.ipynb)\n",
        "- [Getting started with BigQuery](/notebooks/bigquery.ipynb)\n",
        "\n",
        "<div class=\"markdown-google-sans\">\n",
        "\n",
        "### Machine Learning Crash Course\n",
        "\n",
        "<div>\n",
        "\n",
        "These are a few of the notebooks from Google's online Machine Learning course. See the [full course website](https://developers.google.com/machine-learning/crash-course/) for more.\n",
        "- [Intro to Pandas DataFrame](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/pandas_dataframe_ultraquick_tutorial.ipynb)\n",
        "- [Intro to RAPIDS cuDF to accelerate pandas](https://nvda.ws/rapids-cudf)\n",
        "- [Linear regression with tf.keras using synthetic data](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/linear_regression_with_synthetic_data.ipynb)\n",
        "\n",
        "<div class=\"markdown-google-sans\">\n",
        "\n",
        "<a name=\"using-accelerated-hardware\"></a>\n",
        "### Using Accelerated Hardware\n",
        "</div>\n",
        "\n",
        "- [TensorFlow with GPUs](/notebooks/gpu.ipynb)\n",
        "- [TensorFlow with TPUs](/notebooks/tpu.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-H6Lw1vyNNd"
      },
      "source": [
        "<div class=\"markdown-google-sans\">\n",
        "\n",
        "<a name=\"machine-learning-examples\"></a>\n",
        "\n",
        "### Featured examples\n",
        "\n",
        "</div>\n",
        "\n",
        "- [Retraining an Image Classifier](https://tensorflow.org/hub/tutorials/tf2_image_retraining): Build a Keras model on top of a pre-trained image classifier to distinguish flowers.\n",
        "- [Text Classification](https://tensorflow.org/hub/tutorials/tf2_text_classification): Classify IMDB movie reviews as either *positive* or *negative*.\n",
        "- [Style Transfer](https://tensorflow.org/hub/tutorials/tf2_arbitrary_image_stylization): Use deep learning to transfer style between images.\n",
        "- [Multilingual Universal Sentence Encoder Q&A](https://tensorflow.org/hub/tutorials/retrieval_with_tf_hub_universal_encoder_qa): Use a machine learning model to answer questions from the SQuAD dataset.\n",
        "- [Video Interpolation](https://tensorflow.org/hub/tutorials/tweening_conv3d): Predict what happened in a video between the first and the last frame.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}